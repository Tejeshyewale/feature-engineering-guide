# ðŸ› ï¸ Feature Engineering in Machine Learning (Practical Guide)

This document provides a hands-on example of **feature engineering techniques in Python** that you can directly use in your machine learning projects.

---

## ðŸ“Œ What is Feature Engineering?

Feature engineering is the process of transforming raw data into meaningful features that improve machine learning model performance.

Good features > Complex models.

---

## ðŸ“‚ Step 1: Load the Dataset

```python
import pandas as pd

# Load dataset
df = pd.read_csv("data.csv")

# Quick look
df.head()
```

---

## ðŸ§¹ Step 2: Handle Missing Values

### ðŸ”¹ Categorical Columns â†’ Fill with Mode

```python
categorical_cols = df.select_dtypes(include=['object']).columns

for col in categorical_cols:
    df[col].fillna(df[col].mode()[0], inplace=True)
```

### ðŸ”¹ Numerical Columns â†’ Fill with Median

```python
numerical_cols = df.select_dtypes(include=['number']).columns

for col in numerical_cols:
    df[col].fillna(df[col].median(), inplace=True)
```

---

## ðŸ“‰ Step 3: Handle Outliers (Log Transformation)

```python
import numpy as np

skewed_cols = df[numerical_cols].skew().sort_values(ascending=False)
skewed_cols = skewed_cols[abs(skewed_cols) > 1].index

for col in skewed_cols:
    if (df[col] > 0).all():
        df[col] = np.log(df[col])
```

---

## ðŸ—ï¸ Step 4: Create New Features

### Example: House Age from Year Columns

```python
df['HouseAge'] = df['YrSold'] - df['YearBuilt']
df['RemodAge'] = df['YrSold'] - df['YearRemodAdd']
```

### Example: Area Feature

```python
df['TotalArea'] = df['Length'] * df['Width']
```

---

## ðŸ”¤ Step 5: Encode Categorical Variables

### ðŸ”¹ One-Hot Encoding

```python
df = pd.get_dummies(df, drop_first=True)
```

### ðŸ”¹ Target Encoding (For High Cardinality)

```python
target = 'SalePrice'
for col in categorical_cols:
    means = df.groupby(col)[target].mean()
    df[col] = df[col].map(means)
```

---

## âš–ï¸ Step 6: Feature Scaling

### ðŸ”¹ Standardization

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
df[numerical_cols] = scaler.fit_transform(df[numerical_cols])
```

---

## ðŸŽ¯ Step 7: Feature Selection

### ðŸ”¹ Remove Highly Correlated Features

```python
import numpy as np

corr_matrix = df.corr().abs()
upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))

high_corr = [column for column in upper.columns if any(upper[column] > 0.9)]
df.drop(columns=high_corr, inplace=True)
```

---

## ðŸ¤– Dataset Ready for ML

```python
X = df.drop('SalePrice', axis=1)
y = df['SalePrice']
```

You can now train any ML model:

```python
from sklearn.linear_model import LinearRegression

model = LinearRegression()
model.fit(X, y)
```

---

## ðŸš€ Libraries Used

* pandas
* numpy
* scikit-learn

---

## âœ… Summary of Techniques Used

âœ” Missing value handling
âœ” Outlier treatment
âœ” Feature transformation
âœ” Feature creation
âœ” Encoding categorical data
âœ” Feature scaling
âœ” Feature selection

---

ðŸ’¡ Tip: Always perform EDA before feature engineering. Domain knowledge makes features powerful!
